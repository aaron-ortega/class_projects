{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('speeches.pkl', 'rb')\n",
    "speeches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speeches is a list\n",
    "# 1st index contains president, speech, & year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a regular expression\n",
    "remove = re.compile(r\"\"\"\n",
    "    (\n",
    "    [\\n\\r\\x95\\x97\\x80\\x99\\x94]  # delimiters\n",
    "    |[0-9]+[a-zA-Z]+            # ordinal numbers\n",
    "    |\\d.                        # all digits\n",
    "    |[$,+;\\]\"\\[%^&{}:\\-()]          # metacharacters\n",
    "    |[A-Z][a-z]{0,3}\\.          # abbreviations\n",
    "    )\n",
    "\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_count = len(speeches)  # 226 speeches [from Washington to Obama]\n",
    "address = [[]] * speech_count\n",
    "presidents = []\n",
    "year = []\n",
    "\n",
    "# replace expressions w/ single whitespace\n",
    "for i in range(speech_count):\n",
    "    address[i] = remove.sub(' ', speeches[i][1])\n",
    "    presidents.append(speeches[i][0])\n",
    "    year.append(speeches[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_speeches = [[]] * speech_count\n",
    "\n",
    "\"\"\"\n",
    "1. Convert capitalcase to lowercase\n",
    "2. Split each speech w/ period as separator\n",
    "3. Remove empty sentences w/ filter method\n",
    "4. Return list w/ sentences per speech\n",
    "\"\"\"\n",
    "for j in range(speech_count):\n",
    "    parsed_speeches[j] = list(filter(None, address[j].lower().split('.')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, Y):\n",
    "    \"\"\"Computes the linear regression.\"\"\"\n",
    "    \n",
    "    mean_x = np.mean(X)\n",
    "    mean_y = np.mean(Y)\n",
    "    values = len(X)\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    for i in range(values):\n",
    "        numerator += (X[i] - mean_x) * (Y[i] - mean_y)\n",
    "        denominator += (X[i] - mean_x) ** 2\n",
    "    b1 = numerator / denominator\n",
    "    b0 = mean_y - (b1 * mean_x)\n",
    "    \n",
    "    \"\"\"Returns y-intercept and slope\"\"\"\n",
    "    return [b0, b1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of sentences per address\n",
    "num_sentences = np.zeros(len(parsed_speeches))\n",
    "for count in range(speech_count):\n",
    "    num_sentences[count] = len(parsed_speeches[count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert year to numpy array\n",
    "year = np.array(year, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_int, slope = linear_regression(year, num_sentences)\n",
    "model_1 = slope * year + y_int\n",
    "\n",
    "# plotting \n",
    "plt.figure(dpi=100)\n",
    "plt.plot(year, model_1, c='orange')\n",
    "plt.scatter(year, num_sentences)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of sentences')\n",
    "plt.title('Total number of sentences in SOU speeches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear fit does not correctly gauge the trend.\n",
    "<br>Nevertheless, the number of sentences throughout the years have been increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate:\n",
    "1. Average sentence length\n",
    "2. Total words per speech\n",
    "3. Longest and shortest sentences\n",
    "\"\"\"\n",
    "\n",
    "average = np.zeros(speech_count)\n",
    "total_words = np.zeros(speech_count)\n",
    "\n",
    "longest_sentence = 0\n",
    "shortest_sentence = 0\n",
    "tmp = 0\n",
    "\n",
    "for i in range(len(parsed_speeches)):\n",
    "    count = 0\n",
    "    for j in range(len(parsed_speeches[i])):\n",
    "        count += len(parsed_speeches[i][j].split())\n",
    "        \n",
    "        tmp = len(parsed_speeches[i][j].split())\n",
    "        if longest_sentence < tmp:\n",
    "            longest_sentence = tmp\n",
    "            \n",
    "        else:\n",
    "            shortest_sentence = tmp\n",
    "            \n",
    "    total_words[i] = count\n",
    "    average[i] =  total_words[i] / len(parsed_speeches[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_2 = linear_regression(year, average)\n",
    "model_2 = parameters_2[1] * year + parameters_2[0]\n",
    "\n",
    "# plotting \n",
    "plt.figure(dpi=100)\n",
    "plt.scatter(year, average)\n",
    "plt.plot(year, model_2, c='orange')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Sentence Length')\n",
    "#plt.title('Average sentence length in SOU speeches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a decreasing trend on the average sentence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half  = np.where(year < 1913)\n",
    "second_half = np.where(year > 1912)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters_3 = linear_regression(year[first_half[0]], total_words[first_half])\n",
    "model_3 = parameters_3[1] * year[first_half[0]] + parameters_3[0]\n",
    "\n",
    "# plotting \n",
    "plt.figure(dpi=100)\n",
    "plt.scatter(year[first_half[0]], total_words[first_half])\n",
    "plt.plot(year[first_half[0]], model_3, c='orange')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total number of words')\n",
    "plt.title('Word Count in SOUs from 1790 - 1912')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences are gettng shorter, but the words count has been increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_4 = linear_regression(year[second_half[0]], total_words[second_half])\n",
    "model_4 = parameters_4[1] * year[second_half[0]] + parameters_4[0]\n",
    "\n",
    "# plotting \n",
    "plt.figure(dpi=100)\n",
    "plt.scatter(year[second_half[0]], total_words[second_half])\n",
    "plt.plot(year[second_half[0]], model_4, c='orange')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total number of words')\n",
    "plt.title('Word Count in SOUs from 1913 - 2016')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove two outliers\n",
    "outliers = np.where(total_words[second_half] > 2e4)\n",
    "clean_year = np.delete(year[second_half[0]], outliers)\n",
    "clean_total_words = np.delete(total_words[second_half], outliers)\n",
    "\n",
    "# new model\n",
    "parameter_5 = linear_regression(clean_year, clean_total_words)\n",
    "model_5 = parameter_5[1] * clean_year + parameter_5[0]\n",
    "# plotting\n",
    "plt.figure(dpi=100)\n",
    "plt.scatter(clean_year, clean_total_words)\n",
    "plt.plot(clean_year, model_5, c='orange')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total number of words')\n",
    "#plt.title('Word Count in SOUs from 1913 - 2016 [outliers removed]')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two outliers do not allow for a proper viewing, however, it\n",
    "<br>appears that word count for this period has been some what constant.\n",
    "<br>Radio and television could be a factor for this. Speeches now reach the entire \n",
    "<br>country so they have to appeal to the entire spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The longest sentence on average is: {:.2f} words'.format(average.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(average == average.max())  # np.where returns the index of what's inside the parenthesis\n",
    "president_max = speeches[index[0][0]][0]\n",
    "print('This corresponds to president: ', president_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shortest sentence on average is: {:.2f} words'.format(average.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(average == average.min())\n",
    "president_min = speeches[index[0][0]][0]\n",
    "print('This corresponds to president: ', president_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The 25% quantile is: {:.2f}'.format(np.percentile(average, 25)))\n",
    "print('The median is: {:.2f}'.format(np.median(average)))\n",
    "print('The 75% quantile is: {:.2f}'.format(np.percentile(average, 75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The longest sentence ever spoken was:', longest_sentence, 'words')\n",
    "print('The shortest sentence ever spoken was: ', shortest_sentence, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
